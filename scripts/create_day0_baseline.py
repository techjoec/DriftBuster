from __future__ import annotations

import argparse
import json
import os
from collections import Counter, defaultdict
from dataclasses import dataclass
from difflib import SequenceMatcher
from pathlib import Path
from typing import Dict, Iterable, List, Mapping, Optional, Sequence, Tuple

from driftbuster.core.detector import Detector
from driftbuster.reporting.diff import canonicalise_text, canonicalise_xml, build_unified_diff
from driftbuster.reporting.html import render_html_report
from driftbuster.hunt import default_rules, hunt_path


@dataclass
class FileVariant:
    server: str
    path: Path
    format: str
    variant: Optional[str]
    canonical_text: str


def _canonicalise(format_name: str, variant: Optional[str], text: str) -> str:
    fmt = (format_name or "").lower()
    var = (variant or "").lower()
    if fmt == "xml" or "xml" in fmt or "xml" in var:
        return canonicalise_xml(text)
    if fmt == "json" or "json" in fmt or "structured-settings-json" in var:
        try:
            data = json.loads(text)
            return json.dumps(data, ensure_ascii=False, sort_keys=True, separators=(",", ":"))
        except Exception:
            return canonicalise_text(text)
    return canonicalise_text(text)


def _collect_variants(root: Path) -> Dict[str, List[FileVariant]]:
    det = Detector()
    # Identify server directories (one level deep)
    servers = [p for p in sorted(root.iterdir()) if p.is_dir()]
    groups: Dict[str, List[FileVariant]] = defaultdict(list)
    for server in servers:
        server_name = server.name
        for path, match in det.scan_path(server, glob="**/*"):
            if match is None:
                continue
            try:
                rel = path.relative_to(server).as_posix()
            except ValueError:
                rel = path.name
            # Load text for canonicalisation (bounded by detector sampling by default)
            try:
                text = path.read_text(errors="replace")
            except Exception:
                continue
            canon = _canonicalise(match.format_name or "text", match.variant, text)
            groups[rel].append(
                FileVariant(
                    server=server_name,
                    path=path,
                    format=match.format_name,
                    variant=match.variant,
                    canonical_text=canon,
                )
            )
    return groups


def _choose_baseline(variants: List[FileVariant]) -> Tuple[FileVariant, Mapping[str, int]]:
    # Mode by content first
    counts = Counter(v.canonical_text for v in variants)
    most_common_text, _ = counts.most_common(1)[0]
    candidates = [v for v in variants if v.canonical_text == most_common_text]
    if len(candidates) == 1:
        return candidates[0], counts

    # Tie-breaker: choose the one with minimal total edit distance to all others
    def distance(a: str, b: str) -> int:
        sm = SequenceMatcher(None, a, b)
        # approximate: number of non-equal opcodes size
        d = 0
        for tag, i1, i2, j1, j2 in sm.get_opcodes():
            if tag == "equal":
                continue
            d += max(i2 - i1, j2 - j1)
        return d

    best = min(candidates, key=lambda c: sum(distance(c.canonical_text, v.canonical_text) for v in variants))
    return best, counts


def _write_snapshot(root: Path, relative_path: str, content: str) -> Path:
    dest = root / relative_path
    dest.parent.mkdir(parents=True, exist_ok=True)
    dest.write_text(content)
    return dest


def _build_profile_store(baseline_root: Path, decisions: Mapping[str, FileVariant]) -> Mapping[str, object]:
    configs = []
    for rel, var in sorted(decisions.items()):
        expected_variant = var.variant
        expected_format = var.format
        configs.append(
            {
                "id": rel,
                "path": (baseline_root / rel).as_posix(),
                "expected_format": expected_format,
                **({"expected_variant": expected_variant} if expected_variant else {}),
            }
        )
    return {
        "profiles": [
            {
                "name": "day0-baseline",
                "description": "Proposed baseline snapshot generated by DriftBuster",
                "tags": ["env:day0"],
                "configs": configs,
            }
        ]
    }


def main(argv: Optional[Sequence[str]] = None) -> int:
    parser = argparse.ArgumentParser(description="Create a Day 0 baseline from multiple servers")
    parser.add_argument("--root", type=Path, required=True, help="Root containing server directories")
    parser.add_argument("--output", type=Path, default=Path("artifacts/day0-baseline"), help="Output directory for snapshot & reports")
    parser.add_argument("--report", action="store_true", help="Emit an HTML report summarising diffs and hunts")
    args = parser.parse_args(argv)

    servers = [p for p in sorted(args.root.iterdir()) if p.is_dir()]
    if len(servers) < 2:
        print("Expected 2+ server directories under", args.root)
        return 2

    print(f"Scanning {len(servers)} servers under {args.root}…")
    groups = _collect_variants(args.root)
    print(f"Collected {len(groups)} distinct relative paths")

    baseline_root = args.output / "baseline_snapshot"
    baseline_root.mkdir(parents=True, exist_ok=True)

    decisions: Dict[str, FileVariant] = {}
    audit: Dict[str, object] = {}
    diffs_payload: List[Mapping[str, object]] = []

    for rel, variants in sorted(groups.items()):
        chosen, counts = _choose_baseline(variants)
        # write snapshot
        _write_snapshot(baseline_root, rel, chosen.canonical_text)
        decisions[rel] = chosen
        audit[rel] = {
            "chosen_server": chosen.server,
            "format": chosen.format,
            "variant": chosen.variant,
            "counts": dict(counts),
            "servers": [v.server for v in variants],
        }
        # store diffs against chosen for report
        for v in variants:
            if v is chosen:
                continue
            label = f"{rel} — {chosen.server} → {v.server}"
            diff = build_unified_diff(
                chosen.canonical_text,
                v.canonical_text,
                content_type="text" if "xml" not in (chosen.format or "").lower() else "xml",
                from_label=f"{chosen.server}:{rel}",
                to_label=f"{v.server}:{rel}",
                label=label,
            )
            diffs_payload.append({"label": label, "diff": diff.diff, "stats": dict(diff.stats)})

    profile_store = _build_profile_store(baseline_root, decisions)

    # Write outputs
    args.output.mkdir(parents=True, exist_ok=True)
    (args.output / "profile_store.day0.json").write_text(json.dumps(profile_store, ensure_ascii=False, indent=2))
    (args.output / "baseline.decisions.json").write_text(json.dumps(audit, ensure_ascii=False, indent=2))
    print("Wrote:", (args.output / "profile_store.day0.json"))
    print("Wrote:", (args.output / "baseline.decisions.json"))

    if args.report:
        hunts = hunt_path(args.root, rules=default_rules(), glob="**/*", return_json=True)
        html = render_html_report(
            matches=[],
            title="Day 0 Baseline Proposal",
            diffs=diffs_payload,
            profile_summary={},
            hunt_hits=hunts,
            extra_metadata={"server_count": len(servers)},
            warnings=["Proposed baseline for review. Edit decisions.json to override."],
        )
        report_path = args.output / "day0-baseline.html"
        report_path.write_text(html)
        print("Wrote:", report_path)

    print("Baseline snapshot root:", baseline_root)
    return 0


if __name__ == "__main__":
    raise SystemExit(main())

